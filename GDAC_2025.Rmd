---
title: "GDAC"
author: "Varun"
date: "2025-02-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Load Libraries

```{r}

# Load Libraries
library(tidyverse)
library(tictoc)

```


```{r}

GDAC <- read_csv("C:\\Users\\varun\\Box Sync\\Business Analytics Degree\\Semesters\\Spring Semester 2025\\2025_GDAC\\Data\\final_dataset_2025_for_release.csv")


```

# Most Liked Tweets

```{r}

Liked_Tweet <- GDAC %>% 
  group_by(brand) %>% 
  summarize(total_likes = sum(public_metrics.like_count)) %>% 
  arrange(desc(total_likes)) %>% 
  head(n = 10)

# Create a new column to categorize the top 3 brands
Liked_Tweet <- Liked_Tweet %>%
  mutate(Top3 = ifelse(rank(-total_likes) <= 3, "Top 3", "Others"))

# Create the bar plot
ggplot(data = Liked_Tweet, 
       mapping = aes(x = reorder(brand, -total_likes), y = total_likes, fill = Top3)) +
  geom_col() + 
  scale_fill_manual(values = c("Top 3" = "#30F09B", "Other" = "#7898F0")) +  # Customize colors
  labs(title = "Brand With Most Liked Tweets", x = "Brand", y = "Likes") + theme_classic()

#write_csv(Liked_Tweet,"Top_Liked_Tweets.csv")

```

# City with most tweets

```{r}

cities <- read_csv("C:\\Users\\varun\\Box Sync\\Business Analytics Degree\\Semesters\\Spring Semester 2025\\2025_GDAC\\Data\\simplemaps_uscities_basicv1.90\\uscities.csv")

cities <- cities$city_ascii

# Convert keywords to lowercase
cities <- tolower(cities)


# Remove NA values from GDAC location data
loc_noNA <- GDAC %>% filter(!is.na(location)) %>% pull(location) %>% tolower()


# Function to provide total number of rows for each keyword.
# Function to count exact city name matches
calculate_count <- function(keyword) {
  pattern <- paste0("\\b", keyword, "\\b")  # Ensure exact word match
  keyword_count <- sum(str_count(loc_noNA, pattern))  # Count occurrences
  return(keyword_count)
}

# This took 9.5 minutes to run with sapply and str_count
# This took 5.5 minues to run with map_int and str_count
tic()
city_count <- setNames(map_int(cities, calculate_count), cities)
toc()

head(city_count)

# Convert city_count to a dataframe
city_count_df <- tibble(city = names(city_count), count = as.integer(city_count))

city_count_df %>% 
  arrange(desc(count)) %>% 
  head(n=10)

a <- grepl("chicago",loc_noNA,ignore.case = TRUE)
a <- a[which(a == TRUE)]
length(a)
sum(a)

b <- grepl(cities[1],loc_noNA,ignore.case = TRUE)
b <- b[which(b == TRUE)]
length(b)

city_count = vector()


city_count <- sapply(cities, function(city) sum(grepl(city, loc_noNA, ignore.case = TRUE)))

head(city_count)

max(city_count)

GDAC %>% 
  group_by(location) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  head(n=10)


```

# Brand with the most Counts

```{r}
# Keywords
unique_keywords <- unique(GDAC$brand)
unique_keywords <- toupper(unique_keywords)

# Calculate by Count
calculate_count <- function(keyword) {
  keyword_count <- sum(str_detect(toupper(GDAC$text), keyword))
  return(keyword_count)
}

# Calculate by Porportion
calculate_row_proportion <- function(keyword) {
  keyword_count <- sum(str_detect(toupper(GDAC$text), keyword))
  return(keyword_count / nrow(GDAC))
}

# Run both functions
brand_count <- sapply(unique_keywords,calculate_count)
brand_proportion <- sapply(unique_keywords,calculate_row_proportion)


# Convert to Dataframes
brand_count <- tibble(brand = names(brand_count), count = as.integer(brand_count))

brand_proportion <- tibble(brand = names(brand_proportion), count = as.numeric(brand_proportion))

# Organize and show top 10 for proportion and counts

# Top 10 brands by count (Tweets)
brand_count %>% arrange(desc(count)) %>% head(10)  

# Top 10 brands by proportion (Tweets)
brand_proportion %>% arrange(desc(count)) %>% head(10)

# Top 10 brands grouped by brand name
GDAC %>% group_by(brand) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(10)

write.csv(brand_count,"brand_count.csv",row.names = FALSE)


```



# Tweets by Language

```{r}

language <- GDAC %>% 
  group_by(lang) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

head(language, n =10)

```

# Sentiment Analysis

## Sentiment Analysis 01

```{r}

# Convert brand names to uppercase for matching
unique_keywords <- unique(GDAC$brand)
unique_keywords <- toupper(unique_keywords)



# Convert tweet text to uppercase for case-insensitive matching
GDAC <- GDAC %>%
  mutate(assigned_brand = NA_character_)  # Create empty column

# Assign brands to tweets
for (brand in unique_keywords) {
  matched_indices <- str_detect(toupper(GDAC$text), brand)
  GDAC$assigned_brand[matched_indices] <- brand
}

library(sentimentr)

# Some tweets may not match any brand, so we filter them out:
GDAC_filtered <- GDAC %>%
  filter(!is.na(assigned_brand))

GDAC_filtered <- GDAC_filtered %>%
  filter(!is.na(text) & text != "")


brand_sentiment <- GDAC_filtered %>%
  group_by(assigned_brand) %>%
  summarise(sentiment_score = mean(sentiment(text)))

sentiment(GDAC$text[1])


brand_sentiment <- brand_sentiment %>%
  arrange(desc(sentiment_score))  # Sort brands by sentiment

head(brand_sentiment)

```


##Sentiment Analysis 02 with Dictionary

```{r}

# Load Necessary Libraries
library(sentimentr)
library(caret)
library(quanteda)
library(broom)

# Load Dictionaries

positive_words_bing <- scan("C:/Users/varun/Box Sync/Business Analytics Degree/Semesters/Spring Semester 2025/2025_GDAC/Data/positive-words.txt", what = "char", sep = "\n", skip = 35, quiet = T)

negative_words_bing <- scan("C:/Users/varun/Box Sync/Business Analytics Degree/Semesters/Spring Semester 2025/2025_GDAC/Data/negative-words.txt", what = "char", sep = "\n", skip = 35, quiet = T)

sentiment_bing <- dictionary(list(positive = positive_words_bing, negative = negative_words_bing))

# Create Corpus
corp_GDAC <- corpus(GDAC, text_field = "text")

# Sentiment Analysis
dfm_sentiment <- corp_GDAC %>% tokens() %>% dfm %>%  dfm_lookup(sentiment_bing)

dfm_sentiment_df<-convert(dfm_sentiment, to ='data.frame')
dfm_sentiment_df$net<-(dfm_sentiment_df$positive)-(dfm_sentiment_df$negative)

summary(dfm_sentiment_df)

```

## Sentiment Analysis 03 with Sentiment R

```{r}

#unique_keywords <- unique(GDAC$brand)
unique_keywords <- toupper(unique(GDAC$brand))

# Create new columns for each keyword, retaining the keyword name if matched
for (keyword in unique_keywords) {
  GDAC[[paste0("keyword_", keyword)]] <- ifelse(
    str_detect(toupper(GDAC$text), keyword), 
    keyword, 
    NA_character_
  )
}

keyword_col <- colnames(GDAC)[37:94]


# This is how to group the variables
out <- with(
GDAC,
sentiment_by(
get_sentences(text), # Reviews are stored in variable Description
#list(brand) # grouping variables
))
head(out)



combined_data <- cbind(out, GDAC[, 37:94]) # Let's do it in one shot isntead of creating separate variables

#combined_data %>% 
#  group_by(across(all_of(colnames(combined_data)[5:62]))) %>% 
#  summarise(avg_sentiment = mean(ave_sentiment, na.rm = TRUE))

combined_data %>% 
  group_by(`keyword_DUNKIN'`) %>%
  filter(`keyword_DUNKIN'` != "NA") %>% 
  summarise(avg_sentiment = mean(ave_sentiment),
            total_sentiment = sum(ave_sentiment))


sentiment <- function(a){
  a<- sym(a)
  combined_data %>%
    group_by(!! a) %>% 
    filter({{ a }} != "NA") %>% 
    summarise(avg_sentiment = mean(ave_sentiment),
              total_sentiment = sum(ave_sentiment))
}


# Test Function
sentiment("keyword_DUNKIN'")
sentiment("keyword_NOVARTIS")

brand_columns <- colnames(GDAC)[37:94]

# Print the output as a comma-separated list without quotes

brand_sentiment <- lapply(brand_columns,sentiment)

brand_sentiment <- lapply(brand_columns, function(x) {
  df <- sentiment(x)
  df$brand <- x  # Add brand name column
  return(df)
})

brand_sentiment_df <- bind_rows(brand_sentiment)

brand_sentiment_df <- brand_sentiment_df %>% select(avg_sentiment,total_sentiment,brand)

brand_sentiment_df <- brand_sentiment_df %>%
  mutate(brand = gsub("keyword_", "", brand))

brand_sentiment_avg <- brand_sentiment_df %>% 
  arrange(desc(avg_sentiment))

brand_sentiment_total <- brand_sentiment_df %>% 
  arrange(desc(total_sentiment))

write.csv(brand_sentiment_avg,"brand_sentiment_avg.csv",row.names = FALSE)

write.csv(brand_sentiment_total,"brand_sentiment_total.csv",row.names = FALSE)

```

```{r}

keyword_removed_cols <- gsub("keyword_", "", keyword_col)

# Perform sentiment analysis
sentiment_out <- with(
  GDAC,
  sentiment_by(
    get_sentences(), 
    list(`keyword_DUNKIN'`) # Group by both text_id and brand
  )
)



```

```{r}



```

